{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp\n",
    "\n",
    "# Force CPU usage to avoid GPU-related crashes\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# Initialize MediaPipe solutions\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_face = mp.solutions.face_mesh\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "# Set camera resolution (optional but recommended)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# Initialize holistic model\n",
    "with mp_holistic.Holistic(\n",
    "        static_image_mode=False,\n",
    "        model_complexity=1,\n",
    "        smooth_landmarks=True,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to grab frame\")\n",
    "                break\n",
    "\n",
    "            # Convert the BGR image to RGB\n",
    "            img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Process the image and get the result\n",
    "            results = holistic.process(img)\n",
    "\n",
    "            # Convert back to BGR for OpenCV\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Draw face landmarks\n",
    "            if results.face_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    img, results.face_landmarks, mp_face.FACEMESH_TESSELATION)\n",
    "\n",
    "            # Draw left hand landmarks\n",
    "            if results.left_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    img, results.left_hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Draw right hand landmarks\n",
    "            if results.right_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    img, results.right_hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Draw pose landmarks\n",
    "            if results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    img, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "            # Show the final output\n",
    "            cv2.imshow('MediaPipe Holistic', img)\n",
    "\n",
    "            # Break the loop on pressing 'q'\n",
    "            if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "# Initialize MediaPipe\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize variables\n",
    "expression = \"\"\n",
    "result_shown = False\n",
    "last_input_time = 0\n",
    "input_delay = 1.5  # seconds to wait before allowing new input\n",
    "\n",
    "def count_fingers(hand_landmarks):\n",
    "    tips = [4, 8, 12, 16, 20]\n",
    "    count = 0\n",
    "    for tip in tips[1:]:\n",
    "        if hand_landmarks.landmark[tip].y < hand_landmarks.landmark[tip - 2].y:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def detect_operator(hand_landmarks):\n",
    "    # Only thumb up: +\n",
    "    if (hand_landmarks.landmark[4].x < hand_landmarks.landmark[3].x and \n",
    "        all(hand_landmarks.landmark[tip].y > hand_landmarks.landmark[tip - 2].y for tip in [8, 12, 16, 20])):\n",
    "        return '+'\n",
    "    \n",
    "    # Only index up: -\n",
    "    if (hand_landmarks.landmark[8].y < hand_landmarks.landmark[6].y and \n",
    "        all(hand_landmarks.landmark[tip].y > hand_landmarks.landmark[tip - 2].y for tip in [12, 16, 20])):\n",
    "        return '-'\n",
    "\n",
    "    # Victory sign: *\n",
    "    if (hand_landmarks.landmark[8].y < hand_landmarks.landmark[6].y and \n",
    "        hand_landmarks.landmark[12].y < hand_landmarks.landmark[10].y and \n",
    "        all(hand_landmarks.landmark[tip].y > hand_landmarks.landmark[tip - 2].y for tip in [16, 20])):\n",
    "        return '*'\n",
    "\n",
    "    # All fingers up: /\n",
    "    if all(hand_landmarks.landmark[tip].y < hand_landmarks.landmark[tip - 2].y for tip in [8, 12, 16, 20]):\n",
    "        return '/'\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Start webcam and hand detection\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7) as hands:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        image = cv2.flip(frame, 1)\n",
    "        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        result = hands.process(rgb)\n",
    "\n",
    "        current_time = time.time()\n",
    "\n",
    "        if result.multi_hand_landmarks:\n",
    "            hand_landmarks = result.multi_hand_landmarks[0]\n",
    "            mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Detect operator\n",
    "            op = detect_operator(hand_landmarks)\n",
    "            if op and current_time - last_input_time > input_delay:\n",
    "                expression += op\n",
    "                last_input_time = current_time\n",
    "                result_shown = False\n",
    "\n",
    "            # Detect number\n",
    "            elif not op and current_time - last_input_time > input_delay:\n",
    "                fingers = count_fingers(hand_landmarks)\n",
    "                if fingers <= 5:\n",
    "                    expression += str(fingers)\n",
    "                    last_input_time = current_time\n",
    "\n",
    "        # Keyboard inputs\n",
    "        key = cv2.waitKey(10)\n",
    "        if key == ord('r') or key == ord('='):\n",
    "            try:\n",
    "                result = str(eval(expression))\n",
    "                expression += \"=\" + result\n",
    "                result_shown = True\n",
    "            except:\n",
    "                expression = \"Error\"\n",
    "                result_shown = True\n",
    "        elif key == ord('c'):\n",
    "            expression = \"\"\n",
    "            result_shown = False\n",
    "        elif key == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Display expression\n",
    "        cv2.rectangle(image, (0, 0), (640, 50), (0, 0, 0), -1)\n",
    "        cv2.putText(image, expression, (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)\n",
    "        cv2.imshow(\"Gesture Calculator\", image)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
